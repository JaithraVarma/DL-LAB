{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gwe2jnkw0LF1",
        "outputId": "1b8bac13-9776-43f5-c19b-5a8df6f9b29e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb  4 13:48:31 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpgHVulT1arW",
        "outputId": "26558fc5-4f2b-476c-d80e-cba055f3f850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "Collecting mxnet-cu110\n",
            "  Downloading mxnet_cu110-1.9.0-py3-none-manylinux2014_x86_64.whl (325.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 325.4 MB 30 kB/s \n",
            "\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu110) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu110) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu110) (2.10)\n",
            "Installing collected packages: graphviz, mxnet-cu110\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-cu110-1.9.0\n",
            "Collecting gluoncv\n",
            "  Downloading gluoncv-0.10.4.post4-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.62.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.4.1)\n",
            "Collecting yacs\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.13)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.3.5)\n",
            "Collecting autocfg\n",
            "  Downloading autocfg-0.0.8-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from gluoncv) (7.1.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (3.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gluoncv) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (3.0.4)\n",
            "Installing collected packages: yacs, portalocker, autocfg, gluoncv\n",
            "Successfully installed autocfg-0.0.8 gluoncv-0.10.4.post4 portalocker-2.3.2 yacs-0.1.8\n",
            "Collecting decord\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.6 MB 10.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from decord) (1.19.5)\n",
            "Installing collected packages: decord\n",
            "Successfully installed decord-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version \n",
        "!pip install mxnet-cu110   \n",
        "!pip install --upgrade gluoncv\n",
        "!pip install decord"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiZfEZBNh8Mq",
        "outputId": "a5adb544-1241-45ce-877b-c9dd37f6480a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxS277HA1a1-",
        "outputId": "51b8441a-eb15-4c2f-a3c9-d1b1b738fb5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.9.0` and `torch==1.10.0+cu111` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n",
            "  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"
          ]
        }
      ],
      "source": [
        "from __future__ import division\n",
        "\n",
        "import argparse, time, logging, os, sys, math\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pandas\n",
        "from decord import VideoReader\n",
        "\n",
        "import mxnet as mx\n",
        "import gluoncv \n",
        "from mxnet import gluon, nd, init, context\n",
        "from mxnet import autograd as ag\n",
        "from mxnet.gluon import nn\n",
        "from mxnet.gluon.data.vision import transforms\n",
        "\n",
        "from gluoncv.data.transforms import video\n",
        "from gluoncv.data import VideoClsCustom\n",
        "import gluoncv.data \n",
        "from gluoncv.model_zoo import get_model\n",
        "from gluoncv.utils import makedirs, LRSequential, LRScheduler, split_and_load, TrainingHistory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDvazE1j9ieu"
      },
      "source": [
        "Took below code from 7. Fine-tuning SOTA video models on your own dataset\n",
        "(but changed the transform function to the one from 6. Dive Deep into Training SlowFast mdoels on Kinetcis400)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlDbFVeNHW_I"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlbQh0WWHTb8"
      },
      "source": [
        "TRAIN DATA GENRATOR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53ZzhYwe1a8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39599177-9151-4b01-b654-ceafae0f38fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load 1987 training samples.\n"
          ]
        }
      ],
      "source": [
        "#https://medium.com/apache-mxnet/gluoncv-0-6-embrace-video-understanding-49bc10ec1421\n",
        "\n",
        "num_gpus = 1\n",
        "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    # Fix the input video frames size as 256×340 and randomly sample the cropping width and height from\n",
        "    # {256,224,192,168}. After that, resize the cropped regions to 224 × 224.\n",
        "    video.VideoMultiScaleCrop(size=(224, 224), scale_ratios=[1.0, 0.9]), #WAS THIS  scale_ratios=[1.0, 0.875, 0.75, 0.66]\n",
        "    # Randomly flip the video frames horizontally\n",
        "    video.VideoRandomHorizontalFlip(),\n",
        "    # Transpose the video frames from height*width*num_channels to num_channels*height*width\n",
        "    # and map values from [0, 255] to [0,1]\n",
        "    video.VideoToTensor(),\n",
        "    # Normalize the video frames with mean and standard deviation calculated across all images\n",
        "    #video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "per_device_batch_size = 16 #change batch size over here \n",
        "num_workers = 0 # these two lines are used if we were trying to use multiple gpus - so ignore\n",
        "batch_size = per_device_batch_size * num_gpus\n",
        "\n",
        "train_dataset = VideoClsCustom(root=os.path.expanduser('/content/drive/MyDrive/sl_videos/'),#bounded_videos/'),\n",
        "                               setting=os.path.expanduser('/content/drive/MyDrive/sl_videos/new_train.txt'),  #CHANGE\n",
        "                               train=True,\n",
        "                               video_loader=True,\n",
        "                               use_decord=True,\n",
        "                               new_step =2 ,\n",
        "                               new_length=32,\n",
        "                               transform=transform_train\n",
        "                               )\n",
        "print('Load %d training samples.' % len(train_dataset))\n",
        "train_data = gluon.data.DataLoader(train_dataset, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=num_workers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5zjCa1BHYGv"
      },
      "source": [
        "VAL DATA GENERATOR\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLOxBBBvHave",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f69307c0-12db-4e86-dbc6-8851fdc2cd02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load 353 training samples.\n"
          ]
        }
      ],
      "source": [
        "#https://medium.com/apache-mxnet/gluoncv-0-6-embrace-video-understanding-49bc10ec1421\n",
        "\n",
        "num_gpus = 1\n",
        "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    # Fix the input video frames size as 256×340 and randomly sample the cropping width and height from\n",
        "    # {256,224,192,168}. After that, resize the cropped regions to 224 × 224.\n",
        "    video.VideoMultiScaleCrop(size=(224, 224), scale_ratios=[1.0, 0.9]), #WAS THIS  scale_ratios=[1.0, 0.875, 0.75, 0.66]\n",
        "    # Randomly flip the video frames horizontally\n",
        "    video.VideoRandomHorizontalFlip(),\n",
        "    # Transpose the video frames from height*width*num_channels to num_channels*height*width\n",
        "    # and map values from [0, 255] to [0,1]\n",
        "    video.VideoToTensor(),\n",
        "    # Normalize the video frames with mean and standard deviation calculated across all images\n",
        "   # video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "per_device_batch_size =16 #change batch size over here \n",
        "num_workers = 0 # these two lines are used if we were trying to use multiple gpus - so ignore\n",
        "batch_size = per_device_batch_size * num_gpus\n",
        "\n",
        "val_dataset = VideoClsCustom(root=os.path.expanduser('/content/drive/MyDrive/sl_videos/'),#bounded_videos/'),\n",
        "                               setting=os.path.expanduser('/content/drive/MyDrive/sl_videos/new_val.txt'),  #CHANGE\n",
        "                               train=False,\n",
        "                               video_loader=True,\n",
        "                               use_decord=True,\n",
        "                               new_step =2 ,\n",
        "                               new_length=32,\n",
        "                               transform=transform_train\n",
        "                               )\n",
        "\n",
        "\n",
        "print('Load %d training samples.' % len(val_dataset))\n",
        "val_data = gluon.data.DataLoader(val_dataset, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=num_workers)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEptzunA3bXs"
      },
      "source": [
        "will get erroe if you set pretrained = true. Instead you should set pretrained_base = true as we are changing the number of classes "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkLrtAYb3MO7"
      },
      "outputs": [],
      "source": [
        "# kinetics_model = get_model(name='i3d_nl5_resnet50_v1_kinetics400', nclass=400, pretrained=True)\n",
        "net = get_model(name='i3d_nl5_resnet50_v1_kinetics400',nclass=50,pretrained=False,pretrained_base=False,feat_ext=False,partial_bn=True)\n",
        "# source_params = kinetics_model.collect_params()\n",
        "# target_params = net.collect_params()\n",
        "# assert len(source_params.keys()) == len(target_params.keys())\n",
        "\n",
        "# pretrained_weights=[]\n",
        "# for layer_name in source_params.keys():\n",
        "#     pretrained_weights.append(source_params[layer_name].data())\n",
        "\n",
        "# for i, layer_name in enumerate(target_params.keys()):\n",
        "#     if i + 2 == len(source_params.keys()):\n",
        "#         # skip the last dense layer\n",
        "#         break\n",
        "#     target_params[layer_name].set_data(pretrained_weights[i])\n",
        "\n",
        "net.collect_params().reset_ctx(mx.Context('cpu'))\n",
        "net.load_parameters('/content/drive/MyDrive/i3d_nl5_resnet50_v1_kinetics400/i3dnlres50/i3dnlres50_1_epoch_15')\n",
        "net.collect_params().reset_ctx(mx.Context('gpu'))\n",
        "net.collect_params().reset_ctx(ctx)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mx.viz.plot_network(net(mx.sym.var('data'))[0], node_attrs={\"shape\":\"oval\",\"fixedsize\":\"false\"},hide_weights=False,save_format='pdf').render()"
      ],
      "metadata": {
        "id": "RPzoXooQ0FEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qJAna6-5-ST",
        "outputId": "5fb1d905-03ce-48a8-8ea4-68a98439d78d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Block.summary of I3D_ResNetV1(\n",
              "  (first_stage): HybridSequential(\n",
              "    (0): Conv3D(3 -> 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
              "    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "    (2): Activation(relu)\n",
              "    (3): MaxPool3D(size=(1, 3, 3), stride=(2, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
              "  )\n",
              "  (pool2): MaxPool3D(size=(2, 1, 1), stride=(2, 1, 1), padding=(0, 0, 0), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)\n",
              "  (res_layers): HybridSequential(\n",
              "    (0): HybridSequential(\n",
              "      (0): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        )\n",
              "        (conv1): Conv3D(64 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (relu): Activation(relu)\n",
              "        (downsample): HybridSequential(\n",
              "          (0): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=256)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        )\n",
              "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (relu): Activation(relu)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        )\n",
              "        (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "        (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
              "        (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (relu): Activation(relu)\n",
              "      )\n",
              "    )\n",
              "    (1): HybridSequential(\n",
              "      (0): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        )\n",
              "        (conv1): Conv3D(256 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        (relu): Activation(relu)\n",
              "        (downsample): HybridSequential(\n",
              "          (0): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=512)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          (8): NonLocal(\n",
              "            (theta): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (phi): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (g): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (W): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (bn): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "            (W_bn): HybridSequential(\n",
              "              (0): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "              (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        (relu): Activation(relu)\n",
              "        (nonlocal_block): NonLocal(\n",
              "          (theta): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (phi): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (g): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (W): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (bn): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          (W_bn): HybridSequential(\n",
              "            (0): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        )\n",
              "        (conv1): Conv3D(512 -> 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        (relu): Activation(relu)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          (8): NonLocal(\n",
              "            (theta): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (phi): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (g): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (W): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (bn): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "            (W_bn): HybridSequential(\n",
              "              (0): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "              (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
              "        (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        (relu): Activation(relu)\n",
              "        (nonlocal_block): NonLocal(\n",
              "          (theta): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (phi): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (g): Conv3D(512 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (W): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (bn): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          (W_bn): HybridSequential(\n",
              "            (0): Conv3D(256 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): HybridSequential(\n",
              "      (0): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "        )\n",
              "        (conv1): Conv3D(512 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "        (relu): Activation(relu)\n",
              "        (downsample): HybridSequential(\n",
              "          (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=1024)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "          (8): NonLocal(\n",
              "            (theta): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (phi): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (g): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (W): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (bn): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "            (W_bn): HybridSequential(\n",
              "              (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "              (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "        (relu): Activation(relu)\n",
              "        (nonlocal_block): NonLocal(\n",
              "          (theta): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (phi): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (g): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (W): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (bn): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "          (W_bn): HybridSequential(\n",
              "            (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "        )\n",
              "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "        (relu): Activation(relu)\n",
              "      )\n",
              "      (3): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "          (8): NonLocal(\n",
              "            (theta): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (phi): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (g): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (W): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (bn): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "            (W_bn): HybridSequential(\n",
              "              (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "              (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "        (relu): Activation(relu)\n",
              "        (nonlocal_block): NonLocal(\n",
              "          (theta): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (phi): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (g): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (W): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (bn): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "          (W_bn): HybridSequential(\n",
              "            (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (4): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "        )\n",
              "        (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "        (relu): Activation(relu)\n",
              "      )\n",
              "      (5): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "          (8): NonLocal(\n",
              "            (theta): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (phi): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (g): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (W): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (bn): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "            (W_bn): HybridSequential(\n",
              "              (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "              (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (conv1): Conv3D(1024 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
              "        (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "        (relu): Activation(relu)\n",
              "        (nonlocal_block): NonLocal(\n",
              "          (theta): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (phi): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (g): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (W): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "          (bn): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "          (W_bn): HybridSequential(\n",
              "            (0): Conv3D(512 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
              "            (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): HybridSequential(\n",
              "      (0): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
              "        )\n",
              "        (conv1): Conv3D(1024 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
              "        (relu): Activation(relu)\n",
              "        (downsample): HybridSequential(\n",
              "          (0): Conv3D(1024 -> 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=True, in_channels=2048)\n",
              "        )\n",
              "      )\n",
              "      (1): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
              "        )\n",
              "        (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
              "        (relu): Activation(relu)\n",
              "      )\n",
              "      (2): Bottleneck(\n",
              "        (bottleneck): HybridSequential(\n",
              "          (0): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          (2): Activation(relu)\n",
              "          (3): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "          (4): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "          (5): Activation(relu)\n",
              "          (6): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "          (7): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
              "        )\n",
              "        (conv1): Conv3D(2048 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
              "        (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
              "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
              "        (relu): Activation(relu)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (st_avg): GlobalAvgPool3D(size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0), ceil_mode=True, global_pool=True, pool_type=avg, layout=NCDHW)\n",
              "  (head): HybridSequential(\n",
              "    (0): Dropout(p = 0.5, axes=())\n",
              "    (1): Dense(2048 -> 50, linear)\n",
              "  )\n",
              "  (fc): Dense(2048 -> 50, linear)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "net.summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMxhlgHJPh3o"
      },
      "outputs": [],
      "source": [
        "net.collect_params().setattr('grad_req', 'null')\n",
        "net.res_layers[2].collect_params().setattr('grad_req', 'write')\n",
        "net.res_layers[3].collect_params().setattr('grad_req', 'write')\n",
        "net.st_avg.collect_params().setattr('grad_req', 'write')\n",
        "net.head.collect_params().setattr('grad_req', 'write')\n",
        "net.fc.collect_params().setattr('grad_req', 'write')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpA4ZN3n6jvi"
      },
      "outputs": [],
      "source": [
        "net.hybridize()\n",
        "warmup_epoch = 20\n",
        "total_epoch = 75\n",
        "num_batches = len(train_data)\n",
        "\n",
        "scheduler =mx.lr_scheduler.CosineScheduler(max_update=total_epoch, base_lr=1e-4, final_lr=1e-6, warmup_steps=warmup_epoch,  warmup_mode='linear',warmup_begin_lr=1e-4)\n",
        "optimizer = 'Adam'#mxnet.optimizer.Adam(learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08, )\n",
        "# Set parameters\n",
        "#optimizer_params = {'learning_rate':  0.005}  #,'wd': 0.0001, 'momentum': 0.9}\n",
        "#optimizer_params['lr_scheduler'] = lr_scheduler\n",
        "optimizer_params = {'wd': 1e-4}  #,'wd': 0.0001,\n",
        "\n",
        "# Define our trainer for net\n",
        "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)#the set of parameters to optimize\n",
        "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\n",
        "train_metric = mx.metric.Accuracy()\n",
        "val_metric = mx.metric.Accuracy()\n",
        "train_history = TrainingHistory(['training-acc']) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "mrzGzVkJVf3J",
        "outputId": "26aa8afe-20a2-41df-c088-13d530f339ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f81266f7550>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(columns=['epoch','lr'])\n",
        "for i in range(total_epoch):\n",
        "  dictionary = {'epoch':i,'lr':scheduler(i)}\n",
        "  df = df.append(dictionary,ignore_index=True)\n",
        "df.plot(x = 'epoch', y = 'lr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFG7iGVT-Uoa"
      },
      "source": [
        "\n",
        "valid_acc = metric.Accuracy()\n",
        "for data,label in valid_data:\n",
        "    output = network(data)\n",
        "    valid_acc.update(label,output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4at9Q40qZRs_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ead1fb8-18d1-4051-e022-cdb9048294c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0] train=0.510317 val=0.628895 loss=12.451263 lr=0.000100 time: 1354.344388\n",
            "[Epoch 1] train=0.740312 val=0.705382 loss=4.646672 lr=0.000100 time: 421.752964\n",
            "[Epoch 2] train=0.811777 val=0.708215 loss=3.198168 lr=0.000100 time: 422.610981\n",
            "[Epoch 3] train=0.856568 val=0.719547 loss=2.526166 lr=0.000100 time: 424.006567\n",
            "[Epoch 4] train=0.890790 val=0.770538 loss=1.722657 lr=0.000100 time: 422.797879\n",
            "[Epoch 5] train=0.898339 val=0.736544 loss=1.728150 lr=0.000100 time: 421.770709\n",
            "[Epoch 6] train=0.928032 val=0.762040 loss=1.286995 lr=0.000100 time: 424.643880\n",
            "[Epoch 7] train=0.917967 val=0.781870 loss=1.356334 lr=0.000100 time: 424.121970\n",
            "[Epoch 8] train=0.947660 val=0.753541 loss=0.959504 lr=0.000100 time: 424.547592\n",
            "[Epoch 9] train=0.946653 val=0.796034 loss=0.917671 lr=0.000100 time: 424.981571\n",
            "[Epoch 10] train=0.937594 val=0.770538 loss=1.261896 lr=0.000100 time: 426.250147\n",
            "[Epoch 11] train=0.938098 val=0.776204 loss=1.030721 lr=0.000100 time: 428.196226\n",
            "[Epoch 12] train=0.952189 val=0.762040 loss=0.860328 lr=0.000100 time: 426.038735\n",
            "[Epoch 13] train=0.962758 val=0.739377 loss=0.614532 lr=0.000100 time: 426.735517\n",
            "[Epoch 14] train=0.966281 val=0.790368 loss=0.584158 lr=0.000100 time: 427.435120\n",
            "[Epoch 15] train=0.949673 val=0.787535 loss=0.883509 lr=0.000100 time: 427.950011\n",
            "[Epoch 16] train=0.959235 val=0.767705 loss=0.814648 lr=0.000100 time: 428.520978\n",
            "[Epoch 17] train=0.949170 val=0.790368 loss=0.950200 lr=0.000100 time: 427.578197\n",
            "[Epoch 18] train=0.959235 val=0.756374 loss=0.717095 lr=0.000100 time: 428.144054\n",
            "[Epoch 19] train=0.964268 val=0.767705 loss=0.643933 lr=0.000100 time: 428.990797\n",
            "[Epoch 20] train=0.961751 val=0.781870 loss=0.663578 lr=0.000100 time: 428.665745\n",
            "[Epoch 21] train=0.970307 val=0.787535 loss=0.501018 lr=0.000100 time: 430.178130\n",
            "[Epoch 22] train=0.979366 val=0.827195 loss=0.362403 lr=0.000100 time: 428.656823\n",
            "[Epoch 23] train=0.977353 val=0.813031 loss=0.342445 lr=0.000099 time: 428.999814\n",
            "[Epoch 24] train=0.975340 val=0.759207 loss=0.488479 lr=0.000099 time: 429.174960\n",
            "[Epoch 25] train=0.962758 val=0.813031 loss=0.840553 lr=0.000098 time: 430.122299\n",
            "[Epoch 26] train=0.970307 val=0.790368 loss=0.543021 lr=0.000097 time: 429.764421\n",
            "[Epoch 27] train=0.973327 val=0.813031 loss=0.471266 lr=0.000096 time: 429.013121\n",
            "[Epoch 28] train=0.976850 val=0.807365 loss=0.380737 lr=0.000095 time: 430.096153\n",
            "[Epoch 29] train=0.976346 val=0.801700 loss=0.548413 lr=0.000094 time: 429.279063\n",
            "[Epoch 30] train=0.980876 val=0.813031 loss=0.368535 lr=0.000092 time: 427.640368\n",
            "[Epoch 31] train=0.983895 val=0.827195 loss=0.280319 lr=0.000091 time: 432.605075\n",
            "[Epoch 32] train=0.972823 val=0.804533 loss=0.508025 lr=0.000089 time: 431.505174\n",
            "[Epoch 33] train=0.977856 val=0.807365 loss=0.434738 lr=0.000087 time: 428.768853\n",
            "[Epoch 34] train=0.985405 val=0.796034 loss=0.278740 lr=0.000085 time: 431.828672\n",
            "[Epoch 35] train=0.984399 val=0.810198 loss=0.362276 lr=0.000083 time: 428.179300\n",
            "[Epoch 36] train=0.990941 val=0.818697 loss=0.174784 lr=0.000081 time: 431.586076\n",
            "[Epoch 37] train=0.989431 val=0.827195 loss=0.184440 lr=0.000078 time: 431.711274\n",
            "[Epoch 38] train=0.988425 val=0.804533 loss=0.198950 lr=0.000076 time: 431.217158\n",
            "[Epoch 39] train=0.990941 val=0.821530 loss=0.184938 lr=0.000074 time: 427.533820\n",
            "[Epoch 40] train=0.991444 val=0.796034 loss=0.133422 lr=0.000071 time: 428.503535\n",
            "[Epoch 41] train=0.987921 val=0.821530 loss=0.209777 lr=0.000068 time: 429.991843\n",
            "[Epoch 42] train=0.988928 val=0.821530 loss=0.240474 lr=0.000066 time: 428.869062\n",
            "[Epoch 43] train=0.991444 val=0.835694 loss=0.187752 lr=0.000063 time: 427.956215\n",
            "[Epoch 44] train=0.991948 val=0.798867 loss=0.185136 lr=0.000060 time: 427.557303\n",
            "[Epoch 45] train=0.994464 val=0.824363 loss=0.127424 lr=0.000058 time: 429.906028\n",
            "[Epoch 46] train=0.995471 val=0.815864 loss=0.092545 lr=0.000055 time: 431.210685\n",
            "[Epoch 47] train=0.996980 val=0.844193 loss=0.068872 lr=0.000052 time: 426.841553\n",
            "[Epoch 48] train=0.996477 val=0.841360 loss=0.062345 lr=0.000049 time: 427.236224\n",
            "[Epoch 49] train=0.994967 val=0.807365 loss=0.086744 lr=0.000046 time: 428.792612\n",
            "[Epoch 50] train=0.994464 val=0.841360 loss=0.105068 lr=0.000043 time: 432.916566\n",
            "[Epoch 51] train=0.994967 val=0.844193 loss=0.098208 lr=0.000041 time: 431.648357\n",
            "[Epoch 52] train=0.996980 val=0.835694 loss=0.060205 lr=0.000038 time: 431.535013\n",
            "[Epoch 53] train=0.998490 val=0.838527 loss=0.029579 lr=0.000035 time: 429.244843\n",
            "[Epoch 54] train=0.998993 val=0.841360 loss=0.017800 lr=0.000033 time: 422.946510\n",
            "[Epoch 55] train=0.995974 val=0.835694 loss=0.079880 lr=0.000030 time: 423.865173\n",
            "[Epoch 56] train=0.998490 val=0.864023 loss=0.030239 lr=0.000027 time: 427.402370\n",
            "[Epoch 57] train=0.998490 val=0.849858 loss=0.055296 lr=0.000025 time: 427.254172\n",
            "[Epoch 58] train=0.998993 val=0.847025 loss=0.035369 lr=0.000023 time: 426.641996\n",
            "[Epoch 59] train=1.000000 val=0.835694 loss=0.013076 lr=0.000020 time: 425.907630\n",
            "[Epoch 60] train=0.998490 val=0.852691 loss=0.015565 lr=0.000018 time: 426.535686\n",
            "[Epoch 61] train=0.998993 val=0.838527 loss=0.013022 lr=0.000016 time: 426.299391\n",
            "[Epoch 62] train=0.999497 val=0.847025 loss=0.018950 lr=0.000014 time: 424.614354\n",
            "[Epoch 63] train=1.000000 val=0.861190 loss=0.003836 lr=0.000012 time: 426.216394\n",
            "[Epoch 64] train=1.000000 val=0.849858 loss=0.006115 lr=0.000010 time: 425.920719\n",
            "[Epoch 65] train=0.999497 val=0.852691 loss=0.009911 lr=0.000009 time: 427.451461\n"
          ]
        }
      ],
      "source": [
        "epochs = total_epoch\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    lr = scheduler(epoch)\n",
        "    trainer.set_learning_rate(lr)\n",
        "    tic = time.time()\n",
        "    train_metric.reset()\n",
        "    val_metric.reset()\n",
        "    train_loss = 0\n",
        "\n",
        "    # Loop through each batch of training data\n",
        "    for i, batch in enumerate(train_data):\n",
        "        # Extract data and label\n",
        "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        # AutoGrad\n",
        "        with ag.record():\n",
        "            output = []\n",
        "            for _, X in enumerate(data):\n",
        "                X = X.reshape((-1,) + X.shape[2:])\n",
        "                pred = net(X)\n",
        "                output.append(pred)\n",
        "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
        "\n",
        "        # Backpropagation\n",
        "        for l in loss:\n",
        "            l.backward()\n",
        "\n",
        "        # Optimize\n",
        "        trainer.step(batch_size)\n",
        "\n",
        "        # Update metrics\n",
        "        train_loss += sum([l.mean().asscalar() for l in loss])\n",
        "        train_metric.update(label, output)\n",
        "\n",
        "        #if i == 100:\n",
        "         #   break\n",
        "\n",
        "    name, acc = train_metric.get()\n",
        "\n",
        "    #--------------------------------------------------------------------------\n",
        "    for i, batch in enumerate(val_data):\n",
        "        # Extract data and label\n",
        "        data = split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
        "        label = split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
        "\n",
        "        \n",
        "        val_output = []\n",
        "        for _, X in enumerate(data):\n",
        "            X = X.reshape((-1,) + X.shape[2:])\n",
        "            pred = net(X)\n",
        "            val_output.append(pred)\n",
        "            \n",
        "   \n",
        "        val_metric.update(label, val_output)\n",
        "    name_val, val_acc = val_metric.get()\n",
        "\n",
        "    # Update history and print metrics\n",
        "    train_history.update([acc])\n",
        "    print('[Epoch %d] train=%f val=%f loss=%f lr=%f time: %f' %\n",
        "        (epoch, acc, val_acc, train_loss / (i+1),trainer.learning_rate, time.time()-tic))\n",
        "    \n",
        "    if epoch%5==0:\n",
        "      file_name = '/content/drive/MyDrive/i3d_nl5_resnet50_v1_kinetics400/i3dnlres50/i3dnlres50_4secondtry_epoch_'+str(epoch)\n",
        "      net.save_parameters(file_name)\n",
        "# We can plot the metric scores with:\n",
        "train_history.plot()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_rLLgvdWKpyj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}